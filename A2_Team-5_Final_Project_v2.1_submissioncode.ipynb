{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "contrary-sample",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-26T00:01:18.103553Z",
     "start_time": "2021-03-26T00:01:18.096395Z"
    }
   },
   "source": [
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<br><br><br><br><br>\n",
    "<u><b><font size = 6>A2: Team Project OJ </f></b></u><br><br>\n",
    "<b><font size = 5> Data Optimization - DAT-5304 </f></b>\n",
    "<br><br>\n",
    "<b>Authors</b>          : Carolina Novello Moreira, Jack Daoud & Max Lembke <br>\n",
    "<b>Date Created</b> : 03/24/2021<br>\n",
    "<br><br><br><br><br>\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:.9px;border:none;color:#333;background-color:#333;\" />\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-michael",
   "metadata": {},
   "source": [
    "# Set-up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dental-billy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:51:22.646315Z",
     "start_time": "2021-03-31T16:51:20.964565Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import pandas as pd #pandas \n",
    "import numpy  as np #numpy \n",
    "from numpy import arange # for ranges with floats\n",
    "import statsmodels.formula.api as smf # predictive modeling with nice outputs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set options \n",
    "pd.set_option(\"display.max_rows\", 999)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "# Importing file \n",
    "df = pd.read_excel('OJ_Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "extensive-pantyhose",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:51:22.653260Z",
     "start_time": "2021-03-31T16:51:22.647275Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Helper functions \n",
    "\n",
    "# Make binary function \n",
    "def make_binary(df):\n",
    "    \n",
    "    for col in df.columns:\n",
    "        \n",
    "        if 'feat' in col \\\n",
    "        or 'disp' in col:\n",
    "            \n",
    "            for index, value in df.iterrows():\n",
    "                \n",
    "                if df.loc[index, col] >= 0.5:\n",
    "                    df.loc[index, col] = 1\n",
    "                else:\n",
    "                    df.loc[index, col] = 0\n",
    "        \n",
    "            df[col] = df[col].astype(int)\n",
    "\n",
    "\n",
    "# Shuffle dataframe function\n",
    "def shuffle(df, n = 1, axis = 0):     \n",
    "    df = df.copy()\n",
    "    for _ in range(n):\n",
    "        df.apply(np.random.shuffle, axis = axis)\n",
    "        return df\n",
    "\n",
    "# Source:\n",
    "# https://stackoverflow.com/questions/15772009/shuffling-permutating-a-dataframe-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "above-yahoo",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:51:23.017336Z",
     "start_time": "2021-03-31T16:51:22.655254Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data cleaning \n",
    "\n",
    "# Clean binary variables\n",
    "make_binary(df)\n",
    "\n",
    "\n",
    "# Log transformations \n",
    "\n",
    "# Price\n",
    "df['log_price1'] = np.log(df['price1'])\n",
    "df['log_price2'] = np.log(df['price2'])\n",
    "df['log_price3'] = np.log(df['price3'])\n",
    "df['log_price4'] = np.log(df['price4'])\n",
    "df['log_price5'] = np.log(df['price5'])\n",
    "\n",
    "# Sales\n",
    "df['log_sales1'] = np.log(df['sales1'])\n",
    "df['log_sales2'] = np.log(df['sales2'])\n",
    "df['log_sales3'] = np.log(df['sales3'])\n",
    "df['log_sales4'] = np.log(df['sales4'])\n",
    "df['log_sales5'] = np.log(df['sales5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-cabinet",
   "metadata": {},
   "source": [
    "# Part 1: Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-nutrition",
   "metadata": {},
   "source": [
    "## Product 1: Tropicana Premium 64 oz\n",
    "\n",
    "### Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "surprised-pride",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:51:23.022287Z",
     "start_time": "2021-03-31T16:51:23.019295Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # step 1: build a model\n",
    "# lm_best = smf.ols(formula =  \"\"\"log_sales1 ~ log_price1 +\n",
    "#                                         log_price2 +\n",
    "#                                         log_price3 +\n",
    "#                                         log_price4 +\n",
    "#                                         log_price5 +\n",
    "#                                         disp1 +\n",
    "#                                         feat1\"\"\",\n",
    "#                                         data = df)\n",
    "\n",
    "\n",
    "# # step 2: fit the model based on the data\n",
    "# results_1 = lm_best.fit()\n",
    "\n",
    "# # step 3: analyze the summary output\n",
    "# print(results_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "supported-precipitation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:51:23.090380Z",
     "start_time": "2021-03-31T16:51:23.023320Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             log_sales1   R-squared:                       0.793\n",
      "Model:                            OLS   Adj. R-squared:                  0.786\n",
      "Method:                 Least Squares   F-statistic:                     106.5\n",
      "Date:                Wed, 31 Mar 2021   Prob (F-statistic):           4.46e-37\n",
      "Time:                        12:51:23   Log-Likelihood:                -39.767\n",
      "No. Observations:                 116   AIC:                             89.53\n",
      "Df Residuals:                     111   BIC:                             103.3\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      3.0708      0.817      3.759      0.000       1.452       4.690\n",
      "log_price1    -2.6331      0.213    -12.379      0.000      -3.055      -2.212\n",
      "log_price3     0.5614      0.179      3.140      0.002       0.207       0.916\n",
      "disp1         -0.0199      0.088     -0.227      0.821      -0.193       0.154\n",
      "feat1          0.6419      0.095      6.759      0.000       0.454       0.830\n",
      "==============================================================================\n",
      "Omnibus:                        5.505   Durbin-Watson:                   1.715\n",
      "Prob(Omnibus):                  0.064   Jarque-Bera (JB):                8.276\n",
      "Skew:                          -0.053   Prob(JB):                       0.0160\n",
      "Kurtosis:                       4.304   Cond. No.                         122.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Re-running the the regression without variables with p-values above 0.05\n",
    "\n",
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"log_sales1 ~ log_price1 +\n",
    "                                        log_price3 +\n",
    "                                        disp1 +\n",
    "                                        feat1\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_1_opt = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_1_opt.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-cedar",
   "metadata": {},
   "source": [
    "### Gross Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "universal-ceiling",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:51:23.117308Z",
     "start_time": "2021-03-31T16:51:23.092375Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 grmar1   R-squared:                       0.585\n",
      "Model:                            OLS   Adj. R-squared:                  0.582\n",
      "Method:                 Least Squares   F-statistic:                     161.0\n",
      "Date:                Wed, 31 Mar 2021   Prob (F-statistic):           1.55e-23\n",
      "Time:                        12:51:23   Log-Likelihood:                 130.37\n",
      "No. Observations:                 116   AIC:                            -256.7\n",
      "Df Residuals:                     114   BIC:                            -251.2\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.6923      0.112     15.162      0.000       1.471       1.913\n",
      "log_price1     0.4537      0.036     12.687      0.000       0.383       0.525\n",
      "==============================================================================\n",
      "Omnibus:                       14.775   Durbin-Watson:                   0.530\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):                4.631\n",
      "Skew:                           0.080   Prob(JB):                       0.0987\n",
      "Kurtosis:                       2.034   Cond. No.                         52.1\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"grmar1 ~ log_price1\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_grmar_1 = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_grmar_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-fiber",
   "metadata": {},
   "source": [
    "## Product 2: Tropicana Premium 96 oz\n",
    "\n",
    "### Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mobile-madness",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:51:23.128281Z",
     "start_time": "2021-03-31T16:51:23.119303Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# # step 1: build a model\n",
    "# lm_best = smf.ols(formula =  \"\"\"log_sales2 ~ log_price1 +\n",
    "#                                         log_price2 +\n",
    "#                                         log_price3 +\n",
    "#                                         log_price4 +\n",
    "#                                         log_price5 +\n",
    "#                                         disp2 +\n",
    "#                                         feat2\"\"\",\n",
    "#                                         data = df)\n",
    "\n",
    "\n",
    "# # step 2: fit the model based on the data\n",
    "# results_2 = lm_best.fit()\n",
    "\n",
    "# # step 3: analyze the summary output\n",
    "# print(results_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "chief-calvin",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:51:23.175661Z",
     "start_time": "2021-03-31T16:51:23.133266Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             log_sales2   R-squared:                       0.552\n",
      "Model:                            OLS   Adj. R-squared:                  0.536\n",
      "Method:                 Least Squares   F-statistic:                     34.20\n",
      "Date:                Wed, 31 Mar 2021   Prob (F-statistic):           1.39e-18\n",
      "Time:                        12:51:23   Log-Likelihood:                 10.491\n",
      "No. Observations:                 116   AIC:                            -10.98\n",
      "Df Residuals:                     111   BIC:                             2.786\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      5.4557      0.631      8.643      0.000       4.205       6.706\n",
      "log_price1     0.3164      0.110      2.884      0.005       0.099       0.534\n",
      "log_price2    -1.5982      0.225     -7.106      0.000      -2.044      -1.153\n",
      "disp2          0.0305      0.057      0.539      0.591      -0.082       0.143\n",
      "feat2          0.3048      0.070      4.331      0.000       0.165       0.444\n",
      "==============================================================================\n",
      "Omnibus:                        1.401   Durbin-Watson:                   1.260\n",
      "Prob(Omnibus):                  0.496   Jarque-Bera (JB):                0.916\n",
      "Skew:                           0.106   Prob(JB):                        0.633\n",
      "Kurtosis:                       3.380   Cond. No.                         140.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Re-running the the regression without variables with p-values above 0.05\n",
    "\n",
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"log_sales2 ~ log_price1 +\n",
    "                                        log_price2 +\n",
    "                                        disp2 +\n",
    "                                        feat2\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_2_opt = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_2_opt.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-barrel",
   "metadata": {},
   "source": [
    "### Gross Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "strong-jewelry",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:51:23.205581Z",
     "start_time": "2021-03-31T16:51:23.178654Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 grmar2   R-squared:                       0.504\n",
      "Model:                            OLS   Adj. R-squared:                  0.500\n",
      "Method:                 Least Squares   F-statistic:                     116.0\n",
      "Date:                Wed, 31 Mar 2021   Prob (F-statistic):           4.40e-19\n",
      "Time:                        12:51:23   Log-Likelihood:                 197.88\n",
      "No. Observations:                 116   AIC:                            -391.8\n",
      "Df Residuals:                     114   BIC:                            -386.3\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.4363      0.107     13.433      0.000       1.224       1.648\n",
      "log_price2     0.3834      0.036     10.770      0.000       0.313       0.454\n",
      "==============================================================================\n",
      "Omnibus:                        1.543   Durbin-Watson:                   1.053\n",
      "Prob(Omnibus):                  0.462   Jarque-Bera (JB):                1.440\n",
      "Skew:                          -0.270   Prob(JB):                        0.487\n",
      "Kurtosis:                       2.923   Cond. No.                         86.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"grmar2 ~ log_price2\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_grmar_2 = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_grmar_2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-remark",
   "metadata": {},
   "source": [
    "## Product 3: Topicana 64 oz\n",
    "\n",
    "### Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "scheduled-reputation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:51:23.221539Z",
     "start_time": "2021-03-31T16:51:23.207576Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # step 1: build a model\n",
    "# lm_best = smf.ols(formula =  \"\"\"log_sales3 ~ log_price1 +\n",
    "#                                         log_price2 +\n",
    "#                                         log_price3 +\n",
    "#                                         log_price4 +\n",
    "#                                         log_price5 +\n",
    "#                                         disp3 +\n",
    "#                                         feat3\"\"\",\n",
    "#                                         data = df)\n",
    "\n",
    "\n",
    "# # step 2: fit the model based on the data\n",
    "# results_3 = lm_best.fit()\n",
    "\n",
    "# # step 3: analyze the summary output\n",
    "# print(results_3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "living-evans",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:51:23.278393Z",
     "start_time": "2021-03-31T16:51:23.223534Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             log_sales3   R-squared:                       0.705\n",
      "Model:                            OLS   Adj. R-squared:                  0.691\n",
      "Method:                 Least Squares   F-statistic:                     52.46\n",
      "Date:                Wed, 31 Mar 2021   Prob (F-statistic):           1.43e-27\n",
      "Time:                        12:51:23   Log-Likelihood:                -128.44\n",
      "No. Observations:                 116   AIC:                             268.9\n",
      "Df Residuals:                     110   BIC:                             285.4\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      3.0170      2.029      1.487      0.140      -1.004       7.038\n",
      "log_price1     1.3084      0.354      3.694      0.000       0.606       2.010\n",
      "log_price3    -4.3149      0.471     -9.155      0.000      -5.249      -3.381\n",
      "log_price4     1.5322      0.455      3.367      0.001       0.630       2.434\n",
      "disp3          0.1899      0.171      1.110      0.269      -0.149       0.529\n",
      "feat3          1.0187      0.169      6.036      0.000       0.684       1.353\n",
      "==============================================================================\n",
      "Omnibus:                        8.785   Durbin-Watson:                   1.581\n",
      "Prob(Omnibus):                  0.012   Jarque-Bera (JB):                9.531\n",
      "Skew:                           0.499   Prob(JB):                      0.00852\n",
      "Kurtosis:                       3.988   Cond. No.                         171.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Re-running the the regression without variables with p-values above 0.05\n",
    "\n",
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"log_sales3 ~ log_price1 +\n",
    "                                        log_price3 +\n",
    "                                        log_price4 +\n",
    "                                        disp3 +\n",
    "                                        feat3\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_3_opt = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_3_opt.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-confusion",
   "metadata": {},
   "source": [
    "### Gross Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ignored-fifty",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:51:23.309309Z",
     "start_time": "2021-03-31T16:51:23.281387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 grmar3   R-squared:                       0.534\n",
      "Model:                            OLS   Adj. R-squared:                  0.530\n",
      "Method:                 Least Squares   F-statistic:                     130.5\n",
      "Date:                Wed, 31 Mar 2021   Prob (F-statistic):           1.30e-20\n",
      "Time:                        12:51:23   Log-Likelihood:                 132.17\n",
      "No. Observations:                 116   AIC:                            -260.3\n",
      "Df Residuals:                     114   BIC:                            -254.8\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.8110      0.133     13.624      0.000       1.548       2.074\n",
      "log_price3     0.4539      0.040     11.425      0.000       0.375       0.533\n",
      "==============================================================================\n",
      "Omnibus:                        7.207   Durbin-Watson:                   0.605\n",
      "Prob(Omnibus):                  0.027   Jarque-Bera (JB):                7.343\n",
      "Skew:                          -0.616   Prob(JB):                       0.0254\n",
      "Kurtosis:                       2.973   Cond. No.                         66.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"grmar3 ~ log_price3\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_grmar_3 = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_grmar_3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-grade",
   "metadata": {},
   "source": [
    "## Product 4: Minute Maid 64 oz\n",
    "\n",
    "### Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "painful-effectiveness",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:51:23.320280Z",
     "start_time": "2021-03-31T16:51:23.311304Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # step 1: build a model\n",
    "# lm_best = smf.ols(formula =  \"\"\"log_sales4 ~ log_price1 +\n",
    "#                                         log_price2 +\n",
    "#                                         log_price3 +\n",
    "#                                         log_price4 +\n",
    "#                                         log_price5 +\n",
    "#                                         disp4 +\n",
    "#                                         feat4\"\"\",\n",
    "#                                         data = df)\n",
    "\n",
    "\n",
    "# # step 2: fit the model based on the data\n",
    "# results_4 = lm_best.fit()\n",
    "\n",
    "# # step 3: analyze the summary output\n",
    "# print(results_4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "motivated-mention",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:51:23.375648Z",
     "start_time": "2021-03-31T16:51:23.322275Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             log_sales4   R-squared:                       0.751\n",
      "Model:                            OLS   Adj. R-squared:                  0.737\n",
      "Method:                 Least Squares   F-statistic:                     54.78\n",
      "Date:                Wed, 31 Mar 2021   Prob (F-statistic):           1.12e-30\n",
      "Time:                        12:51:23   Log-Likelihood:                -74.809\n",
      "No. Observations:                 116   AIC:                             163.6\n",
      "Df Residuals:                     109   BIC:                             182.9\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      5.9598      1.488      4.005      0.000       3.011       8.909\n",
      "log_price1     0.5653      0.238      2.376      0.019       0.094       1.037\n",
      "log_price3     0.6214      0.259      2.397      0.018       0.108       1.135\n",
      "log_price4    -2.6623      0.382     -6.976      0.000      -3.419      -1.906\n",
      "log_price5     0.5762      0.207      2.783      0.006       0.166       0.987\n",
      "disp4          0.1964      0.132      1.492      0.138      -0.064       0.457\n",
      "feat4          0.8731      0.130      6.724      0.000       0.616       1.131\n",
      "==============================================================================\n",
      "Omnibus:                       29.629   Durbin-Watson:                   1.828\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               63.769\n",
      "Skew:                           1.013   Prob(JB):                     1.42e-14\n",
      "Kurtosis:                       6.015   Cond. No.                         234.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Re-running the the regression without variables with p-values above 0.05\n",
    "\n",
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"log_sales4 ~ log_price1 +\n",
    "                                        log_price3 +\n",
    "                                        log_price4 +\n",
    "                                        log_price5 +\n",
    "                                        disp4 +\n",
    "                                        feat4\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_4_opt = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_4_opt.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-anatomy",
   "metadata": {},
   "source": [
    "### Gross Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "greatest-tongue",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:51:23.402789Z",
     "start_time": "2021-03-31T16:51:23.377643Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 grmar4   R-squared:                       0.486\n",
      "Model:                            OLS   Adj. R-squared:                  0.482\n",
      "Method:                 Least Squares   F-statistic:                     108.0\n",
      "Date:                Wed, 31 Mar 2021   Prob (F-statistic):           3.39e-18\n",
      "Time:                        12:51:23   Log-Likelihood:                 130.48\n",
      "No. Observations:                 116   AIC:                            -257.0\n",
      "Df Residuals:                     114   BIC:                            -251.5\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.7289      0.142     12.159      0.000       1.447       2.011\n",
      "log_price4     0.4398      0.042     10.391      0.000       0.356       0.524\n",
      "==============================================================================\n",
      "Omnibus:                        0.240   Durbin-Watson:                   0.721\n",
      "Prob(Omnibus):                  0.887   Jarque-Bera (JB):                0.325\n",
      "Skew:                          -0.104   Prob(JB):                        0.850\n",
      "Kurtosis:                       2.845   Cond. No.                         70.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"grmar4 ~ log_price4\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_grmar_4 = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_grmar_4.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-bulgaria",
   "metadata": {},
   "source": [
    "## Product 5: Dominick's 64 oz\n",
    "\n",
    "### Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "liable-consent",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:51:23.414760Z",
     "start_time": "2021-03-31T16:51:23.404783Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # step 1: build a model\n",
    "# lm_best = smf.ols(formula =  \"\"\"log_sales5 ~ log_price1 +\n",
    "#                                         log_price2 +\n",
    "#                                         log_price3 +\n",
    "#                                         log_price4 +\n",
    "#                                         log_price5 +\n",
    "#                                         disp5 +\n",
    "#                                         feat5\"\"\",\n",
    "#                                         data = df)\n",
    "\n",
    "\n",
    "# # step 2: fit the model based on the data\n",
    "# results_5 = lm_best.fit()\n",
    "\n",
    "# # step 3: analyze the summary output\n",
    "# print(results_5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "structured-contamination",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:51:23.474616Z",
     "start_time": "2021-03-31T16:51:23.416752Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             log_sales5   R-squared:                       0.667\n",
      "Model:                            OLS   Adj. R-squared:                  0.649\n",
      "Method:                 Least Squares   F-statistic:                     36.39\n",
      "Date:                Wed, 31 Mar 2021   Prob (F-statistic):           6.66e-24\n",
      "Time:                        12:51:23   Log-Likelihood:                -118.19\n",
      "No. Observations:                 116   AIC:                             250.4\n",
      "Df Residuals:                     109   BIC:                             269.7\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.6726      2.141     -0.314      0.754      -4.915       3.570\n",
      "log_price2    -1.6261      0.595     -2.733      0.007      -2.806      -0.447\n",
      "log_price3     1.0544      0.364      2.900      0.005       0.334       1.775\n",
      "log_price4     1.1239      0.389      2.893      0.005       0.354       1.894\n",
      "log_price5    -3.2319      0.349     -9.272      0.000      -3.923      -2.541\n",
      "disp5          0.2854      0.143      1.999      0.048       0.002       0.568\n",
      "feat5          0.6610      0.154      4.291      0.000       0.356       0.966\n",
      "==============================================================================\n",
      "Omnibus:                        4.516   Durbin-Watson:                   1.680\n",
      "Prob(Omnibus):                  0.105   Jarque-Bera (JB):                4.471\n",
      "Skew:                          -0.274   Prob(JB):                        0.107\n",
      "Kurtosis:                       3.790   Cond. No.                         230.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Re-running the the regression without variables with p-values above 0.05\n",
    "\n",
    "# step 1: build a model\n",
    "lm_best_opt = smf.ols(formula =  \"\"\"log_sales5 ~ log_price2 +\n",
    "                                        log_price3 +\n",
    "                                        log_price4 +\n",
    "                                        log_price5 +\n",
    "                                        disp5 +\n",
    "                                        feat5\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_5_opt = lm_best_opt.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_5_opt.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-cambodia",
   "metadata": {},
   "source": [
    "### Gross Margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fleet-vertex",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:51:23.509523Z",
     "start_time": "2021-03-31T16:51:23.476612Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 grmar5   R-squared:                       0.527\n",
      "Model:                            OLS   Adj. R-squared:                  0.522\n",
      "Method:                 Least Squares   F-statistic:                     126.8\n",
      "Date:                Wed, 31 Mar 2021   Prob (F-statistic):           3.16e-20\n",
      "Time:                        12:51:23   Log-Likelihood:                 105.93\n",
      "No. Observations:                 116   AIC:                            -207.9\n",
      "Df Residuals:                     114   BIC:                            -202.4\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.0035      0.152     13.164      0.000       1.702       2.305\n",
      "log_price5     0.4695      0.042     11.260      0.000       0.387       0.552\n",
      "==============================================================================\n",
      "Omnibus:                        2.499   Durbin-Watson:                   0.750\n",
      "Prob(Omnibus):                  0.287   Jarque-Bera (JB):                2.330\n",
      "Skew:                           0.020   Prob(JB):                        0.312\n",
      "Kurtosis:                       3.693   Cond. No.                         65.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# step 1: build a model\n",
    "lm_best = smf.ols(formula =  \"\"\"grmar5 ~ log_price5\"\"\",\n",
    "                                        data = df)\n",
    "\n",
    "\n",
    "# step 2: fit the model based on the data\n",
    "results_grmar_5 = lm_best.fit()\n",
    "\n",
    "# step 3: analyze the summary output\n",
    "print(results_grmar_5.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-worst",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Part 2: Monte Carlo\n",
    "\n",
    "## Constant Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "excited-annual",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:51:23.608259Z",
     "start_time": "2021-03-31T16:51:23.512515Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Setup constant variables\n",
    "\n",
    "# (Re-) Setting Seed, due to np limitations\n",
    "np.random.seed(42)  \n",
    "\n",
    "# Devisor for sigma \n",
    "\n",
    "d_sigma = 2 \n",
    "\n",
    "# Ounces per SKU\n",
    "oz_1 = 64\n",
    "oz_2 = 96\n",
    "oz_3 = 64\n",
    "oz_4 = 64\n",
    "oz_5 = 64\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################\n",
    "# Historical Data Overview #\n",
    "############################\n",
    "\n",
    "# Average price per SKU\n",
    "price1_avg = round((df['price1'].mean() * oz_1),2)\n",
    "price2_avg = round((df['price2'].mean() * oz_2),2)\n",
    "price3_avg = round((df['price3'].mean() * oz_2),2)\n",
    "price4_avg = round((df['price4'].mean() * oz_4),2)\n",
    "price5_avg = round((df['price5'].mean() * oz_5),2)\n",
    "\n",
    "# Units sold per SKU\n",
    "units_sold_1 = round(df['sales1'].mean(),2)\n",
    "units_sold_2 = round(df['sales2'].mean(),2)\n",
    "units_sold_3 = round(df['sales3'].mean(),2)\n",
    "units_sold_4 = round(df['sales4'].mean(),2)\n",
    "units_sold_5 = round(df['sales5'].mean(),2)\n",
    "\n",
    "# Average gross margin per SKU\n",
    "grmar1_avg = round(df['grmar1'].mean()*100,2)\n",
    "grmar2_avg = round(df['grmar2'].mean()*100,2)\n",
    "grmar3_avg = round(df['grmar3'].mean()*100,2)\n",
    "grmar4_avg = round(df['grmar4'].mean()*100,2)\n",
    "grmar5_avg = round(df['grmar5'].mean()*100,2)\n",
    "\n",
    "# Revenue per SKU \n",
    "revenue_1 = df['sales1'] * oz_1 * df['price1']\n",
    "avg_revenue_1 = round(revenue_1.mean(),2)\n",
    "\n",
    "revenue_2 = df['sales2'] * oz_2 * df['price2']\n",
    "avg_revenue_2 = round(revenue_2.mean(),2)\n",
    "\n",
    "revenue_3 = df['sales3'] * oz_3 * df['price3']\n",
    "avg_revenue_3 = round(revenue_3.mean(),2)\n",
    "\n",
    "revenue_4 = df['sales4'] * oz_4 * df['price4']\n",
    "avg_revenue_4 = round(revenue_4.mean(),2)\n",
    "\n",
    "revenue_5 = df['sales5'] * oz_5 * df['price5']\n",
    "avg_revenue_5 = round(revenue_5.mean(),2)\n",
    "\n",
    "\n",
    "# Profits per SKU\n",
    "profits_1 = revenue_1 * df['grmar1']\n",
    "avg_profits_1 = round(profits_1.mean(),2)\n",
    "\n",
    "profits_2 = revenue_2 * df['grmar2']\n",
    "avg_profits_2 = round(profits_2.mean(),2)\n",
    "\n",
    "profits_3 = revenue_3 * df['grmar3']\n",
    "avg_profits_3 = round(profits_3.mean(),2)\n",
    "\n",
    "profits_4 = revenue_4 * df['grmar4']\n",
    "avg_profits_4 = round(profits_4.mean(),2)\n",
    "\n",
    "profits_5 = revenue_5 * df['grmar5']\n",
    "avg_profits_5 = round(profits_5.mean(),2)\n",
    "\n",
    "total_profits = profits_1 + profits_2 + profits_3 + profits_4 + profits_5\n",
    "avg_total_profits = round(total_profits.mean(),2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################\n",
    "#  Gross Margin  #\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU1 (GRMAR)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_GR1    = results_grmar_1.params[0]  # coefficient from regression\n",
    "intercept_sigma_GR1 = results_grmar_1.bse[0]     # standard error from regression\n",
    "\n",
    "# gross margin\n",
    "B1_mu_GR1    = results_grmar_1.params[1]\n",
    "B1_sigma_GR1 = results_grmar_1.bse[1]\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU2 (GRMAR)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_GR2    = results_grmar_2.params[0]  # coefficient from regression\n",
    "intercept_sigma_GR2 = results_grmar_2.bse[0]    # standard error from regression\n",
    "\n",
    "# gross margin\n",
    "B1_mu_GR2    = results_grmar_2.params[1]\n",
    "B1_sigma_GR2 = results_grmar_2.bse[1]\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU3 (GRMAR)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_GR3    = results_grmar_3.params[0]  # coefficient from regression\n",
    "intercept_sigma_GR3 = results_grmar_3.bse[0]     # standard error from regression\n",
    "\n",
    "# gross margin\n",
    "B1_mu_GR3    = results_grmar_3.params[1]\n",
    "B1_sigma_GR3 = results_grmar_3.bse[1]\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU4 (GRMAR)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_GR4    = results_grmar_4.params[0]  # coefficient from regression\n",
    "intercept_sigma_GR4 = results_grmar_4.bse[0]     # standard error from regression\n",
    "\n",
    "# gross margin\n",
    "B1_mu_GR4    = results_grmar_4.params[1]\n",
    "B1_sigma_GR4 = results_grmar_4.bse[1]\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU5 (GRMAR)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_GR5    = results_grmar_5.params[0]  # coefficient from regression\n",
    "intercept_sigma_GR5 = results_grmar_5.bse[0]     # standard error from regression\n",
    "\n",
    "# gross margin\n",
    "B1_mu_GR5    = results_grmar_5.params[1]\n",
    "B1_sigma_GR5 = results_grmar_5.bse[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########\n",
    "#  Sales  #\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU1 (Sales)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_1    = results_1_opt.params[0]          # coefficient from regression\n",
    "intercept_sigma_1 = results_1_opt.bse[0]/d_sigma     # standard error from regression\n",
    "\n",
    "# price SKU1\n",
    "B1_mu_P1_1    = results_1_opt.params[1]              # coefficient from regression\n",
    "B1_sigma_P1_1 = results_1_opt.bse[1]/d_sigma         # standard error from regression\n",
    "\n",
    "# price SKU3\n",
    "B2_mu_P3_1    = results_1_opt.params[2]              # coefficient from regression\n",
    "B2_sigma_P3_1 = results_1_opt.bse[2]/d_sigma         # standard error from regression\n",
    "\n",
    "# disp1 SKU1\n",
    "B3_mu_D1_1 = results_1_opt.params[3]                 # coefficient from regression\n",
    "\n",
    "# feat1 SKU1\n",
    "B4_mu_F1_1 = results_1_opt.params[4]                 # coefficient from regression\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU2 (Sales)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_2    = results_2_opt.params[0]         # coefficient from regression\n",
    "intercept_sigma_2 = results_2_opt.bse[0]/d_sigma    # standard error from regression\n",
    "\n",
    "# price SKU1\n",
    "B1_mu_P1_2    = results_2_opt.params[1]             # coefficient from regression\n",
    "B1_sigma_P1_2 = results_2_opt.bse[1]/d_sigma        # standard error from regression\n",
    "\n",
    "# price SKU2\n",
    "B2_mu_P2_2    = results_2_opt.params[2]             # coefficient from regression\n",
    "B2_sigma_P2_2 = results_2_opt.bse[2]/d_sigma        # standard error from regression\n",
    "\n",
    "# disp2 SKU2\n",
    "B3_mu_D2_2 = results_2_opt.params[3]                # coefficient from regression\n",
    "\n",
    "# feat2 SKU2\n",
    "B4_mu_F2_2 = results_2_opt.params[4]                # coefficient from regression\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU3 (Sales)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_3    = results_3_opt.params[0]          # coefficient from regression\n",
    "intercept_sigma_3 = results_3_opt.bse[0]/d_sigma     # standard error from regression\n",
    "\n",
    "# price SKU1\n",
    "B1_mu_P1_3    = results_3_opt.params[1]              # coefficient from regression\n",
    "B1_sigma_P1_3 = results_3_opt.bse[1]/d_sigma         # standard error from regression\n",
    "\n",
    "# price SKU3 \n",
    "B2_mu_P3_3    = results_3_opt.params[2]              # coefficient from regression\n",
    "B2_sigma_P3_3 = results_3_opt.bse[2]/d_sigma         # standard error from regression\n",
    "\n",
    "# feat2 SKU4\n",
    "B3_mu_P4_3    = results_3_opt.params[3]              # coefficient from regression\n",
    "B3_sigma_P4_3 = results_3_opt.bse[3]/d_sigma         # standard error from regression\n",
    "\n",
    "# disp3 SKU3\n",
    "B4_mu_D3_3 = results_3_opt.params[4]                 # coefficient from regression\n",
    "\n",
    "# feat3 SKU3\n",
    "B5_mu_F3_3 = results_3_opt.params[5]                 # coefficient from regression\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU4 (Sales)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_4    = results_4_opt.params[0]          # coefficient from regression\n",
    "intercept_sigma_4 = results_4_opt.bse[0]/d_sigma     # standard error from regression\n",
    "\n",
    "# price SKU1\n",
    "B1_mu_P1_4    = results_4_opt.params[1]              # coefficient from regression\n",
    "B1_sigma_P1_4 = results_4_opt.bse[1]/d_sigma         # standard error from regression\n",
    "\n",
    "# price SKU3\n",
    "B2_mu_P3_4    = results_4_opt.params[2]              # coefficient from regression\n",
    "B2_sigma_P3_4 = results_4_opt.bse[2]/d_sigma         # standard error from regression\n",
    "\n",
    "# price  SKU4\n",
    "B3_mu_P4_4    = results_4_opt.params[3]              # coefficient from regression\n",
    "B3_sigma_P4_4 = results_4_opt.bse[3]/d_sigma         # standard error from regression\n",
    "\n",
    "# price SKU5\n",
    "B4_mu_P5_4    = results_4_opt.params[4]              # coefficient from regression\n",
    "B4_sigma_P5_4 = results_4_opt.bse[4]/d_sigma         # standard error from regression\n",
    "\n",
    "# disp4 SKU4\n",
    "B5_mu_D4_4 = results_4_opt.params[5]                 # coefficient from regression\n",
    "\n",
    "# feat4 SKU4\n",
    "B6_mu_F4_4 = results_4_opt.params[6]                 # coefficient from regression\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Set up random draw parameters for coefficients - SKU5 (Sales)\n",
    "\n",
    "# intercept \n",
    "intercept_mu_5    = results_5_opt.params[0]          # coefficient from regression\n",
    "intercept_sigma_5 = results_5_opt.bse[0]/d_sigma     # standard error from regression\n",
    "\n",
    "# price SKU2\n",
    "B1_mu_P2_5    = results_5_opt.params[1]              # coefficient from regression\n",
    "B1_sigma_P2_5 = results_5_opt.bse[1]/d_sigma         # standard error from regression\n",
    "\n",
    "# price SKU3\n",
    "B2_mu_P3_5    = results_5_opt.params[2]              # coefficient from regression\n",
    "B2_sigma_P3_5 = results_5_opt.bse[2]/d_sigma         # standard error from regression\n",
    "\n",
    "# price SKU4\n",
    "B3_mu_P4_5    = results_5_opt.params[3]              # coefficient from regression\n",
    "B3_sigma_P4_5 = results_5_opt.bse[3]/d_sigma             # standard error from regression\n",
    "\n",
    "# price SKU5\n",
    "B4_mu_P5_5    = results_5_opt.params[4]              # coefficient from regression\n",
    "B4_sigma_P5_5 = results_5_opt.bse[4]/d_sigma         # standard error from regression\n",
    "\n",
    "# disp SKU5\n",
    "B5_mu_D5_5    = results_5_opt.params[5]              # coefficient from regression\n",
    "\n",
    "# feat5 SKU5\n",
    "B6_mu_F5_5    = results_5_opt.params[6]              # coefficient from regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-glasgow",
   "metadata": {},
   "source": [
    "## Price & Marketing Settings Determination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "behind-lightning",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:51:23.723466Z",
     "start_time": "2021-03-31T16:51:23.611251Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Price & Marketing Setting Generation \n",
    "\n",
    "# (Re-) Setting Seed, due to np limitations\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of combinations of prices and marketing settings across SKUs'\n",
    "n = 10\n",
    "\n",
    "\n",
    "###########\n",
    "#  Price  #\n",
    "###########\n",
    "\n",
    "# Min Max Prices for SKU#\n",
    "min_price1 = df['price1'].min()\n",
    "max_price1 = df['price1'].max()\n",
    "min_price2 = df['price2'].min()\n",
    "max_price2 = df['price2'].max()\n",
    "min_price3 = df['price3'].min()\n",
    "max_price3 = df['price3'].max()\n",
    "min_price4 = df['price4'].min()\n",
    "max_price4 = df['price4'].max()\n",
    "min_price5 = df['price5'].min()\n",
    "max_price5 = df['price5'].max()\n",
    "\n",
    "# Calculating price increments \n",
    "price_increment_1 = (max_price1 - min_price1)/n\n",
    "price_increment_2 = (max_price2 - min_price2)/n\n",
    "price_increment_3 = (max_price3 - min_price3)/n\n",
    "price_increment_4 = (max_price4 - min_price4)/n\n",
    "price_increment_5 = (max_price5 - min_price5)/n\n",
    "\n",
    "# Instantiating a df to store the prices \n",
    "price_msettings_df = pd.DataFrame()\n",
    "\n",
    "# Generating price \n",
    "price_msettings_df['P_1'] = arange(min_price1, max_price1, price_increment_1)\n",
    "price_msettings_df['P_2'] = arange(min_price2, max_price2, price_increment_2)\n",
    "price_msettings_df['P_3'] = arange(min_price3, max_price3, price_increment_3)\n",
    "price_msettings_df['P_4'] = arange(min_price4, max_price4, price_increment_4)\n",
    "price_msettings_df['P_5'] = arange(min_price5, max_price5, price_increment_5)\n",
    "\n",
    "# Shuffeling\n",
    "\n",
    "# Defining how many shuffles \n",
    "num_s = 10 \n",
    "\n",
    "# Shuffeling\n",
    "price_msettings_df = shuffle(df = price_msettings_df, n = num_s)\n",
    "\n",
    "\n",
    "#######################\n",
    "#  Marketing Setting  #\n",
    "#######################\n",
    "\n",
    "# Setting options \n",
    "options = ([0, 0, 1, 0, 0])\n",
    "\n",
    "# Instantiating empty df to append to \n",
    "df_temp_feat = pd.DataFrame() #feat settings \n",
    "df_temp_disp = pd.DataFrame() #disp setting \n",
    "\n",
    "# Looping to populate df for feat\n",
    "for i in range(n):\n",
    "    temp_v = np.random.choice(options,size = 5,replace=False)\n",
    "    temp_v_l = temp_v.tolist()\n",
    "    temp_v_l_df = DataFrame(temp_v_l).transpose()\n",
    "    df_temp_feat = df_temp_feat.append(temp_v_l_df)\n",
    "\n",
    "# Looping to populate df for disp\n",
    "for i in range(n):\n",
    "    temp_v = np.random.choice(options,size = 5,replace=False)\n",
    "    temp_v_l = temp_v.tolist()\n",
    "    temp_v_l_df = DataFrame(temp_v_l).transpose()\n",
    "    df_temp_disp = df_temp_disp.append(temp_v_l_df)\n",
    "    \n",
    "# Reindexing both df\n",
    "df_temp_feat = df_temp_feat.reset_index(drop=True)\n",
    "df_temp_disp = df_temp_disp.reset_index(drop=True)\n",
    "\n",
    "# Renaming the respective columns \n",
    "df_temp_feat.columns = ['feat1', 'feat2','feat3','feat4','feat5']\n",
    "df_temp_disp.columns = ['disp1', 'disp2','disp3','disp4','disp5']\n",
    "\n",
    "# Merge all created dfs \n",
    "price_msettings_df = pd.concat([price_msettings_df,df_temp_disp, df_temp_feat], axis=1)\n",
    "\n",
    "# Checking df \n",
    "#price_msettings_df.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-fifteen",
   "metadata": {},
   "source": [
    "## Profits Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-college",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T02:21:24.384533Z",
     "start_time": "2021-03-31T02:21:12.731206Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Monte Carlo Simulation\n",
    "\n",
    "# (Re-) Setting Seed, due to np limitations\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of simulations per combinations of prices across SKUs'\n",
    "number_sims = 10_000\n",
    "\n",
    "# Store results from each simulation here\n",
    "final_stats = []\n",
    "\n",
    "# Loop over price dataframe\n",
    "for i in tqdm(range(len(price_msettings_df))):\n",
    "    \n",
    "    # Extract price per SKU as log\n",
    "    P_1 = np.log(price_msettings_df.iloc[i, 0])\n",
    "    P_2 = np.log(price_msettings_df.iloc[i, 1])\n",
    "    P_3 = np.log(price_msettings_df.iloc[i, 2])\n",
    "    P_4 = np.log(price_msettings_df.iloc[i, 3])\n",
    "    P_5 = np.log(price_msettings_df.iloc[i, 4])\n",
    "    \n",
    "    # Extract marketing settings per SKU \n",
    "    disp1 = price_msettings_df.iloc[i, 5]\n",
    "    disp2 = price_msettings_df.iloc[i, 6]\n",
    "    disp3 = price_msettings_df.iloc[i, 7]\n",
    "    disp4 = price_msettings_df.iloc[i, 8]\n",
    "    disp5 = price_msettings_df.iloc[i, 9]\n",
    "    \n",
    "    feat1 = price_msettings_df.iloc[i, 10]\n",
    "    feat2 = price_msettings_df.iloc[i, 11]\n",
    "    feat3 = price_msettings_df.iloc[i, 12]\n",
    "    feat4 = price_msettings_df.iloc[i, 13]\n",
    "    feat5 = price_msettings_df.iloc[i, 14]\n",
    "    \n",
    "    # Placeholder\n",
    "    all_stats = []\n",
    "\n",
    "    # Begin Simulation Loop\n",
    "    for i in range(number_sims):\n",
    "        \n",
    "        ###########\n",
    "        #  SKU1   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_1 = np.random.normal(intercept_mu_1, intercept_sigma_1)\n",
    "        B1_1   = np.random.normal(B1_mu_P1_1, B1_sigma_P1_1)\n",
    "        B2_1   = np.random.normal(B2_mu_P3_1, B2_sigma_P3_1)\n",
    "        \n",
    "        sales_1 = np.exp(intercept_1 \\\n",
    "                + B1_1 * P_1 \\\n",
    "                + B2_1 * P_3 \\\n",
    "                + B3_mu_D1_1 * disp1 \\\n",
    "                + B4_mu_F1_1 * feat1)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR1 = np.random.normal(intercept_mu_GR1, intercept_sigma_GR1)\n",
    "        B1_GR1   = np.random.normal(B1_mu_GR1, B1_sigma_GR1)\n",
    "        \n",
    "        grmar_1 = intercept_GR1 + B1_GR1 * P_1\n",
    "        \n",
    "        # Profit\n",
    "        revenue_1 = sales_1 * oz_1 * np.exp(P_1)\n",
    "        profits_1 = revenue_1 * grmar_1\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU2   # \n",
    "        ###########\n",
    "\n",
    "        # Sales\n",
    "        intercept_2 = np.random.normal(intercept_mu_2, intercept_sigma_2)\n",
    "        B1_2   = np.random.normal(B1_mu_P1_2, B1_sigma_P1_2)\n",
    "        B2_2   = np.random.normal(B2_mu_P2_2, B2_sigma_P2_2)   \n",
    "        \n",
    "        sales_2 = np.exp(intercept_2 \\\n",
    "                + B1_2 * P_1 \\\n",
    "                + B2_2 * P_2 \\\n",
    "                + B3_mu_D2_2 * disp2 \\\n",
    "                + B4_mu_F2_2 * feat2)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR2 = np.random.normal(intercept_mu_GR2, intercept_sigma_GR2)\n",
    "        B1_GR2   = np.random.normal(B1_mu_GR2, B1_sigma_GR2)\n",
    "        \n",
    "        grmar_2 = intercept_GR2 + B1_GR2 * P_2\n",
    "        \n",
    "        # Profit\n",
    "        revenue_2 = sales_2 * oz_2 * np.exp(P_2)\n",
    "        profits_2 = revenue_2 * grmar_2\n",
    "        \n",
    "                \n",
    "        ###########\n",
    "        #  SKU3   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_3 = np.random.normal(intercept_mu_3, intercept_sigma_3)\n",
    "        B1_3   = np.random.normal(B1_mu_P1_3, B1_sigma_P1_3)\n",
    "        B2_3   = np.random.normal(B2_mu_P3_3, B2_sigma_P3_3)   \n",
    "        B3_3   = np.random.normal(B3_mu_P4_3, B3_sigma_P4_3) \n",
    "\n",
    "        sales_3 = np.exp(intercept_3 \\\n",
    "                + B1_3 * P_1 \\\n",
    "                + B2_3 * P_3 \\\n",
    "                + B3_3 * P_4 \\\n",
    "                + B4_mu_D3_3 * disp3 \\\n",
    "                + B5_mu_F3_3 * feat3)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR3 = np.random.normal(intercept_mu_GR3, intercept_sigma_GR3)\n",
    "        B1_GR3   = np.random.normal(B1_mu_GR3, B1_sigma_GR3)\n",
    "        \n",
    "        grmar_3 = intercept_GR3 + B1_GR3 * P_3\n",
    "        \n",
    "        # Profit\n",
    "        revenue_3 = sales_3 * oz_3 * np.exp(P_3)\n",
    "        profits_3 = revenue_3 * grmar_3\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU4   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_4 = np.random.normal(intercept_mu_4, intercept_sigma_4)\n",
    "        B1_4   = np.random.normal(B1_mu_P1_4, B1_sigma_P1_4)\n",
    "        B2_4   = np.random.normal(B2_mu_P3_4, B2_sigma_P3_4)   \n",
    "        B3_4   = np.random.normal(B3_mu_P4_4, B3_sigma_P4_4) \n",
    "        B4_4   = np.random.normal(B4_mu_P5_4, B4_sigma_P5_4)\n",
    "        \n",
    "        sales_4 = np.exp(intercept_4 \\\n",
    "                + B1_4 * P_1 \\\n",
    "                + B2_4 * P_3 \\\n",
    "                + B3_4 * P_4 \\\n",
    "                + B4_4 * P_5 \\\n",
    "                + B5_mu_D4_4 * disp4 \\\n",
    "                + B6_mu_F4_4 * feat4)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR4 = np.random.normal(intercept_mu_GR4, intercept_sigma_GR4)\n",
    "        B1_GR4   = np.random.normal(B1_mu_GR4, B1_sigma_GR4)\n",
    "        \n",
    "        grmar_4 = intercept_GR4 + B1_GR4 * P_4\n",
    "        \n",
    "        # Profit\n",
    "        revenue_4 = sales_4 * oz_4 * np.exp(P_4)\n",
    "        profits_4 = revenue_4 * grmar_4\n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        #  SKU5   # \n",
    "        ###########\n",
    "        \n",
    "        # Sales\n",
    "        intercept_5 = np.random.normal(intercept_mu_5, intercept_sigma_5)\n",
    "        B1_5   = np.random.normal(B1_mu_P2_5, B1_sigma_P2_5)\n",
    "        B2_5   = np.random.normal(B2_mu_P3_5, B2_sigma_P3_5)   \n",
    "        B3_5   = np.random.normal(B3_mu_P4_5, B3_sigma_P4_5) \n",
    "        B4_5   = np.random.normal(B4_mu_P5_5, B4_sigma_P5_5) \n",
    "        \n",
    "        sales_5 = np.exp(intercept_5 \\\n",
    "                + B1_5 * P_2 \\\n",
    "                + B2_5 * P_3 \\\n",
    "                + B3_5 * P_4 \\\n",
    "                + B4_5 * P_5 \\\n",
    "                + B5_mu_D5_5 * disp5 \\\n",
    "                + B6_mu_F5_5 * feat5)\n",
    "        \n",
    "        # Gross Margin\n",
    "        intercept_GR5 = np.random.normal(intercept_mu_GR5, intercept_sigma_GR5)\n",
    "        B1_GR5   = np.random.normal(B1_mu_GR5, B1_sigma_GR5)\n",
    "        \n",
    "        grmar_5 = intercept_GR5 + B1_GR5 * P_5\n",
    "        \n",
    "        # Profit\n",
    "        revenue_5 = sales_5 * oz_5 * np.exp(P_5)\n",
    "        profits_5 = revenue_5 * grmar_5\n",
    "        \n",
    "        \n",
    "        ####################\n",
    "        #  Appending SKUs  # \n",
    "        ####################\n",
    "        \n",
    "        all_stats.append([sales_1, revenue_1, profits_1, grmar_1,\n",
    "                          sales_2, revenue_2, profits_2, grmar_2,\n",
    "                          sales_3, revenue_3, profits_3, grmar_3,\n",
    "                          sales_4, revenue_4, profits_4, grmar_4,\n",
    "                          sales_5, revenue_5, profits_5, grmar_5])\n",
    "    \n",
    "    results_df = pd.DataFrame.from_records(all_stats,  columns = \n",
    "    ['units_sold_1','revenue_1','profits_1', 'grmar_1',\n",
    "     'units_sold_2','revenue_2','profits_2', 'grmar_2',\n",
    "     'units_sold_3','revenue_3','profits_3', 'grmar_3',\n",
    "     'units_sold_4','revenue_4','profits_4', 'grmar_4',\n",
    "     'units_sold_5','revenue_5','profits_5', 'grmar_5',])\n",
    "        \n",
    "    final_stats.append([np.exp(P_1), np.exp(P_2), np.exp(P_3),\n",
    "                        np.exp(P_4), np.exp(P_5),\n",
    "                        results_df['units_sold_1'].mean(),\n",
    "                        results_df['units_sold_2'].mean(),\n",
    "                        results_df['units_sold_3'].mean(),\n",
    "                        results_df['units_sold_4'].mean(),\n",
    "                        results_df['units_sold_5'].mean(),\n",
    "                        results_df['grmar_1'].mean(),\n",
    "                        results_df['grmar_2'].mean(),\n",
    "                        results_df['grmar_3'].mean(),\n",
    "                        results_df['grmar_4'].mean(),\n",
    "                        results_df['grmar_5'].mean(),\n",
    "                        results_df['profits_1'].mean(),\n",
    "                        results_df['profits_2'].mean(),\n",
    "                        results_df['profits_3'].mean(),\n",
    "                        results_df['profits_4'].mean(),\n",
    "                        results_df['profits_5'].mean(),\n",
    "                        feat1,feat2,feat3,feat4,feat5,\n",
    "                        disp1,disp2,disp3,disp4,disp5])\n",
    "    \n",
    "final_stats_df = pd.DataFrame.from_records(final_stats, columns =\n",
    "                ['Price per Oz_1', 'Price per Oz_2',\n",
    "                 'Price per Oz_3', 'Price per Oz_4', 'Price per Oz_5',\n",
    "                 'Sales_1', 'Sales_2', 'Sales_3', 'Sales_4', 'Sales_5',\n",
    "                 'GrMar_1', 'GrMar_2', 'GrMar_3', 'GrMar_4', 'GrMar_5',\n",
    "                 'Profits_1', 'Profits_2', \n",
    "                 'Profits_3', 'Profits_4', 'Profits_5',\n",
    "                 'Feat_1', 'Feat_2', 'Feat_3', 'Feat_4', 'Feat_5',\n",
    "                 'Disp_1', 'Disp_2', 'Disp_3', 'Disp_4', 'Disp_5'])\n",
    "\n",
    "final_stats_df['Total Profits'] = final_stats_df['Profits_5']\\\n",
    "                                + final_stats_df['Profits_4']\\\n",
    "                                + final_stats_df['Profits_3']\\\n",
    "                                + final_stats_df['Profits_2']\\\n",
    "                                + final_stats_df['Profits_1']\n",
    "\n",
    "\n",
    "# Check optimal simulations & price/marketing combinations\n",
    "#final_stats_df\n",
    "\n",
    "# Identify Best Pricing & Marketing Settings for Maximum Profit\n",
    "index = final_stats_df.loc[final_stats_df['Total Profits'] == final_stats_df['Total Profits'].max(),:].index\n",
    "optimized_values = round(final_stats_df.iloc[index,:],2)\n",
    "\n",
    "\n",
    "\n",
    "# Print overview of historical data & optimized data\n",
    "print(f\"\"\"\n",
    "Historical Data\n",
    "----------------\n",
    "\n",
    "Products         Avg Prices         Avg Sales        Avg Revenue       Avg Gross Margin    Avg Profits\n",
    "---------        -----------        ---------        -----------       ----------------   -------------\n",
    "SKU1             ${price1_avg}               {units_sold_1}          ${avg_revenue_1}         {grmar1_avg}%             ${avg_profits_1}                    \n",
    "SKU2             ${price2_avg}               {units_sold_2}          ${avg_revenue_2}         {grmar2_avg}%             ${avg_profits_2}\n",
    "SKU3             ${price3_avg}              {units_sold_3}          ${avg_revenue_3}         {grmar3_avg}%             ${avg_profits_3}\n",
    "SKU4             ${price4_avg}              {units_sold_4}           ${avg_revenue_4}         {grmar4_avg}%             ${avg_profits_4}\n",
    "SKU5             ${price5_avg}              {units_sold_5}           ${avg_revenue_5}          {grmar5_avg}%             ${avg_profits_5}\n",
    "\n",
    "\n",
    "Total Average Profits: ${avg_total_profits}\n",
    "\n",
    "\n",
    "\n",
    "Optimized Data\n",
    "----------------\n",
    "\n",
    "Products         Avg Prices         Avg Sales        Avg Revenue     Avg Gross Margin    Avg Profits\n",
    "---------        -----------        ---------        -----------     ----------------   -------------\n",
    "SKU1             ${optimized_values.iloc[0,0]*oz_1}              {optimized_values.iloc[0,5]}           ${round(optimized_values.iloc[0,5]*optimized_values.iloc[0,10],2)}        {round(optimized_values.iloc[0,10]*100,2)}%              ${optimized_values.iloc[0,15]}                    \n",
    "SKU2             ${optimized_values.iloc[0,1]*oz_2}              {optimized_values.iloc[0,6]}          ${round(optimized_values.iloc[0,6]*optimized_values.iloc[0,11],2)}        {round(optimized_values.iloc[0,11]*100,2)}%              ${optimized_values.iloc[0,16]}\n",
    "SKU3             ${optimized_values.iloc[0,2]*oz_3}              {optimized_values.iloc[0,7]}          ${round(optimized_values.iloc[0,7]*optimized_values.iloc[0,12],2)}       {round(optimized_values.iloc[0,12]*100,2)}%              ${optimized_values.iloc[0,17]}\n",
    "SKU4             ${optimized_values.iloc[0,3]*oz_4}              {optimized_values.iloc[0,8]}           ${round(optimized_values.iloc[0,8]*optimized_values.iloc[0,13],2)}        {round(optimized_values.iloc[0,13]*100,2)}%              ${optimized_values.iloc[0,18]}\n",
    "SKU5             ${optimized_values.iloc[0,4]*oz_5}              {optimized_values.iloc[0,9]}           ${round(optimized_values.iloc[0,9]*optimized_values.iloc[0,14],2)}        {round(optimized_values.iloc[0,14]*100,2)}%              ${optimized_values.iloc[0,19]}\n",
    "\n",
    "\n",
    "Total Average Profits: ${optimized_values.iloc[0,30]}\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-force",
   "metadata": {},
   "source": [
    "# Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-worse",
   "metadata": {},
   "source": [
    "## Reading & Combination of File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "medical-northern",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:56:02.015166Z",
     "start_time": "2021-03-31T16:56:01.980754Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading two results files\n",
    "Top2500 = pd.read_csv('results_2500_top.csv')\n",
    "Bottom2500 = pd.read_csv('results_2500_bottom.csv')\n",
    "\n",
    "# Combining both files \n",
    "all_results = pd.concat([Top2500,Bottom2500])\n",
    "\n",
    "# Renaming \n",
    "final_stats_df = all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-narrow",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "equipped-centre",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:59:54.827127Z",
     "start_time": "2021-03-31T16:59:54.806181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price per Oz_1</th>\n",
       "      <th>Price per Oz_2</th>\n",
       "      <th>Price per Oz_3</th>\n",
       "      <th>Price per Oz_4</th>\n",
       "      <th>Price per Oz_5</th>\n",
       "      <th>Sales_1</th>\n",
       "      <th>Sales_2</th>\n",
       "      <th>Sales_3</th>\n",
       "      <th>Sales_4</th>\n",
       "      <th>Sales_5</th>\n",
       "      <th>GrMar_1</th>\n",
       "      <th>GrMar_2</th>\n",
       "      <th>GrMar_3</th>\n",
       "      <th>GrMar_4</th>\n",
       "      <th>GrMar_5</th>\n",
       "      <th>Profits_1</th>\n",
       "      <th>Profits_2</th>\n",
       "      <th>Profits_3</th>\n",
       "      <th>Profits_4</th>\n",
       "      <th>Profits_5</th>\n",
       "      <th>Feat_1</th>\n",
       "      <th>Feat_2</th>\n",
       "      <th>Feat_3</th>\n",
       "      <th>Feat_4</th>\n",
       "      <th>Feat_5</th>\n",
       "      <th>Disp_1</th>\n",
       "      <th>Disp_2</th>\n",
       "      <th>Disp_3</th>\n",
       "      <th>Disp_4</th>\n",
       "      <th>Disp_5</th>\n",
       "      <th>Total Profits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>0.045478</td>\n",
       "      <td>0.038059</td>\n",
       "      <td>0.038454</td>\n",
       "      <td>0.046421</td>\n",
       "      <td>0.021558</td>\n",
       "      <td>14175.999771</td>\n",
       "      <td>18665.022153</td>\n",
       "      <td>13713.30688</td>\n",
       "      <td>6886.225694</td>\n",
       "      <td>334762.288018</td>\n",
       "      <td>0.28927</td>\n",
       "      <td>0.183535</td>\n",
       "      <td>0.33216</td>\n",
       "      <td>0.378328</td>\n",
       "      <td>0.201668</td>\n",
       "      <td>11955.55907</td>\n",
       "      <td>12558.651041</td>\n",
       "      <td>11264.747953</td>\n",
       "      <td>7745.238142</td>\n",
       "      <td>91494.571411</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135018.767618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price per Oz_1  Price per Oz_2  Price per Oz_3  Price per Oz_4  \\\n",
       "806        0.045478        0.038059        0.038454        0.046421   \n",
       "\n",
       "     Price per Oz_5       Sales_1       Sales_2      Sales_3      Sales_4  \\\n",
       "806        0.021558  14175.999771  18665.022153  13713.30688  6886.225694   \n",
       "\n",
       "           Sales_5  GrMar_1   GrMar_2  GrMar_3   GrMar_4   GrMar_5  \\\n",
       "806  334762.288018  0.28927  0.183535  0.33216  0.378328  0.201668   \n",
       "\n",
       "       Profits_1     Profits_2     Profits_3    Profits_4     Profits_5  \\\n",
       "806  11955.55907  12558.651041  11264.747953  7745.238142  91494.571411   \n",
       "\n",
       "     Feat_1  Feat_2  Feat_3  Feat_4  Feat_5  Disp_1  Disp_2  Disp_3  Disp_4  \\\n",
       "806       0       0       0       0       1       0       0       0       0   \n",
       "\n",
       "     Disp_5  Total Profits  \n",
       "806       1  135018.767618  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify Best Pricing & Marketing Settings for Maximum Profit for SKU5\n",
    "index = final_stats_df.loc[final_stats_df['Total Profits'] == final_stats_df['Total Profits'].max(),:].index\n",
    "final_stats_df.iloc[index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "specialized-capacity",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T16:56:03.131721Z",
     "start_time": "2021-03-31T16:56:03.116727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Historical Data\n",
      "----------------\n",
      "\n",
      "Products         Avg Prices         Avg Sales        Avg Revenue       Avg Gross Margin    Avg Profits\n",
      "---------        -----------        ---------        -----------       ----------------   -------------\n",
      "SKU1             $2.9               18879.45          $46837.53         27.93%             $10371.23                    \n",
      "SKU2             $4.8               11763.31          $55066.02         28.56%             $15365.26\n",
      "SKU3             $3.45              14898.21          $29585.95         29.46%             $6109.05\n",
      "SKU4             $2.27              18481.1           $36706.64         25.34%             $7331.11\n",
      "SKU5             $1.71              15358.9           $22432.1          29.29%             $4858.12\n",
      "\n",
      "\n",
      "Total Average Profits: $44034.76\n",
      "\n",
      "\n",
      "\n",
      "Optimized Data\n",
      "----------------\n",
      "\n",
      "Products         Avg Prices         Avg Sales        Avg Revenue     Avg Gross Margin    Avg Profits\n",
      "---------        -----------        ---------        -----------     ----------------   -------------\n",
      "SKU1             $3.2              14176.0           $4111.04        29.0%              $11955.56                    \n",
      "SKU2             $3.84              18665.02          $3359.7        18.0%              $12558.65\n",
      "SKU3             $2.56              13713.31          $4525.39       33.0%              $11264.75\n",
      "SKU4             $3.2              6886.23           $2616.77        38.0%              $7745.24\n",
      "SKU5             $1.28              334762.29           $66952.46        20.0%              $91494.57\n",
      "\n",
      "\n",
      "Total Average Profits: $135018.77\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identify Best Pricing & Marketing Settings for Maximum Profit\n",
    "index = final_stats_df.loc[final_stats_df['Total Profits'] == final_stats_df['Total Profits'].max(),:].index\n",
    "optimized_values = round(final_stats_df.iloc[index,:],2)\n",
    "\n",
    "# Print overview of historical data & optimized data\n",
    "print(f\"\"\"\n",
    "Historical Data\n",
    "----------------\n",
    "\n",
    "Products         Avg Prices         Avg Sales        Avg Revenue       Avg Gross Margin    Avg Profits\n",
    "---------        -----------        ---------        -----------       ----------------   -------------\n",
    "SKU1             ${price1_avg}               {units_sold_1}          ${avg_revenue_1}         {grmar1_avg}%             ${avg_profits_1}                    \n",
    "SKU2             ${price2_avg}               {units_sold_2}          ${avg_revenue_2}         {grmar2_avg}%             ${avg_profits_2}\n",
    "SKU3             ${price3_avg}              {units_sold_3}          ${avg_revenue_3}         {grmar3_avg}%             ${avg_profits_3}\n",
    "SKU4             ${price4_avg}              {units_sold_4}           ${avg_revenue_4}         {grmar4_avg}%             ${avg_profits_4}\n",
    "SKU5             ${price5_avg}              {units_sold_5}           ${avg_revenue_5}          {grmar5_avg}%             ${avg_profits_5}\n",
    "\n",
    "\n",
    "Total Average Profits: ${avg_total_profits}\n",
    "\n",
    "\n",
    "\n",
    "Optimized Data\n",
    "----------------\n",
    "\n",
    "Products         Avg Prices         Avg Sales        Avg Revenue     Avg Gross Margin    Avg Profits\n",
    "---------        -----------        ---------        -----------     ----------------   -------------\n",
    "SKU1             ${optimized_values.iloc[0,0]*oz_1}              {optimized_values.iloc[0,5]}           ${round(optimized_values.iloc[0,5]*optimized_values.iloc[0,10],2)}        {round(optimized_values.iloc[0,10]*100,2)}%              ${optimized_values.iloc[0,15]}                    \n",
    "SKU2             ${optimized_values.iloc[0,1]*oz_2}              {optimized_values.iloc[0,6]}          ${round(optimized_values.iloc[0,6]*optimized_values.iloc[0,11],2)}        {round(optimized_values.iloc[0,11]*100,2)}%              ${optimized_values.iloc[0,16]}\n",
    "SKU3             ${optimized_values.iloc[0,2]*oz_3}              {optimized_values.iloc[0,7]}          ${round(optimized_values.iloc[0,7]*optimized_values.iloc[0,12],2)}       {round(optimized_values.iloc[0,12]*100,2)}%              ${optimized_values.iloc[0,17]}\n",
    "SKU4             ${optimized_values.iloc[0,3]*oz_4}              {optimized_values.iloc[0,8]}           ${round(optimized_values.iloc[0,8]*optimized_values.iloc[0,13],2)}        {round(optimized_values.iloc[0,13]*100,2)}%              ${optimized_values.iloc[0,18]}\n",
    "SKU5             ${optimized_values.iloc[0,4]*oz_5}              {optimized_values.iloc[0,9]}           ${round(optimized_values.iloc[0,9]*optimized_values.iloc[0,14],2)}        {round(optimized_values.iloc[0,14]*100,2)}%              ${optimized_values.iloc[0,19]}\n",
    "\n",
    "\n",
    "Total Average Profits: ${optimized_values.iloc[0,30]}\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-nerve",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-advisory",
   "metadata": {},
   "source": [
    "## Manual Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-niger",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T22:33:15.864154Z",
     "start_time": "2021-03-29T22:33:14.564984Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Monte Carlo Simulation Manual Parameters\n",
    "\n",
    "# (Re-) Setting Seed, due to np limitations\n",
    "np.random.seed(42)\n",
    "\n",
    "# Extract price per SKU as log\n",
    "P_1 = np.log(price_msettings_df.iloc[0, 0])\n",
    "P_2 = np.log(price_msettings_df.iloc[0, 1])\n",
    "P_3 = np.log(price_msettings_df.iloc[0, 2])\n",
    "P_4 = np.log(price_msettings_df.iloc[0, 3])\n",
    "P_5 = np.log(price_msettings_df.iloc[0, 4])\n",
    "\n",
    "# Extract marketing settings per SKU \n",
    "disp1 = price_msettings_df.iloc[0, 5]\n",
    "feat1 = price_msettings_df.iloc[0, 6]\n",
    "disp2 = price_msettings_df.iloc[0, 7]\n",
    "feat2 = price_msettings_df.iloc[0, 8]\n",
    "disp3 = price_msettings_df.iloc[0, 9]\n",
    "feat3 = price_msettings_df.iloc[0, 10]\n",
    "disp4 = price_msettings_df.iloc[0, 11]\n",
    "feat4 = price_msettings_df.iloc[0, 12]\n",
    "disp5 = price_msettings_df.iloc[0, 13]\n",
    "feat5 = price_msettings_df.iloc[0, 14]\n",
    "    \n",
    "\n",
    "# Number of simulations per combinations of prices across SKUs'\n",
    "number_sims = 10_000\n",
    "\n",
    "# Store results from each simulation here\n",
    "final_stats_2 = []\n",
    "    \n",
    "# Placeholder\n",
    "all_stats_2 = []\n",
    "\n",
    "# Begin Simulation Loop\n",
    "for i in tqdm(range(number_sims)):\n",
    "\n",
    "    ###########\n",
    "    #  SKU1   # \n",
    "    ###########\n",
    "\n",
    "    intercept_1 = np.random.normal(intercept_mu_1, intercept_sigma_1)\n",
    "    B1_1   = np.random.normal(B1_mu_P1_1, B1_sigma_P1_1)\n",
    "    B2_1   = np.random.normal(B2_mu_P3_1, B2_sigma_P3_1)   \n",
    "\n",
    "    sales_1 = np.exp(intercept_1 \\\n",
    "            + B1_1 * P_1 \\\n",
    "            + B2_1 * P_3 \\\n",
    "            + B3_mu_D1_1 * disp1 \\\n",
    "            + B4_mu_F1_1 * feat1)\n",
    "    revenue_1 = sales_1 * oz_1 * np.exp(P_1)\n",
    "    profits_1 = revenue_1 * grmar1_avg\n",
    "\n",
    "\n",
    "    ###########\n",
    "    #  SKU2   # \n",
    "    ###########\n",
    "\n",
    "    intercept_2 = np.random.normal(intercept_mu_2, intercept_sigma_2)\n",
    "    B1_2   = np.random.normal(B1_mu_P1_2, B1_sigma_P1_2)\n",
    "    B2_2   = np.random.normal(B2_mu_P2_2, B2_sigma_P2_2)  \n",
    "\n",
    "    sales_2 = np.exp(intercept_2 \\\n",
    "            + B1_2 * P_1 \\\n",
    "            + B2_2 * P_2 \\\n",
    "            + B3_mu_D2_2 * disp2 \\\n",
    "            + B4_mu_F2_2 * feat2)\n",
    "\n",
    "    revenue_2 = sales_2 * oz_2 * np.exp(P_2)\n",
    "    profits_2 = revenue_2 * grmar2_avg\n",
    "\n",
    "\n",
    "    ###########\n",
    "    #  SKU3   # \n",
    "    ###########\n",
    "\n",
    "    intercept_3 = np.random.normal(intercept_mu_3, intercept_sigma_3)\n",
    "    B1_3   = np.random.normal(B1_mu_P1_3, B1_sigma_P1_3)\n",
    "    B2_3   = np.random.normal(B2_mu_P3_3, B2_sigma_P3_3)   \n",
    "    B3_3   = np.random.normal(B3_mu_P4_3, B3_sigma_P4_3) \n",
    "    \n",
    "    sales_3 = np.exp(intercept_3 \\\n",
    "            + B1_3 * P_1 \\\n",
    "            + B2_3 * P_3 \\\n",
    "            + B3_3 * P_4 \\\n",
    "            + B4_mu_D3_3 * disp3 \\\n",
    "            + B5_mu_F3_3 * feat3)\n",
    "\n",
    "    revenue_3 = sales_3 * oz_3 * np.exp(P_3)\n",
    "    profits_3 = revenue_3 * grmar3_avg\n",
    "\n",
    "\n",
    "    ###########\n",
    "    #  SKU4   # \n",
    "    ###########\n",
    "\n",
    "    intercept_4 = np.random.normal(intercept_mu_4, intercept_sigma_4)\n",
    "    B1_4   = np.random.normal(B1_mu_P1_4, B1_sigma_P1_4)\n",
    "    B2_4   = np.random.normal(B2_mu_P3_4, B2_sigma_P3_4)   \n",
    "    B3_4   = np.random.normal(B3_mu_P4_4, B3_sigma_P4_5) \n",
    "    B4_4   = np.random.normal(B4_mu_P5_5, B4_sigma_P5_5)\n",
    "\n",
    "    sales_4 = np.exp(intercept_4 \\\n",
    "            + B1_4 * P_1 \\\n",
    "            + B2_4 * P_3 \\\n",
    "            + B3_4 * P_4 \\\n",
    "            + B4_4 * P_5 \\\n",
    "            + B5_mu_D4_4 * disp4 \\\n",
    "            + B6_mu_F4_4 * feat4)\n",
    "\n",
    "    revenue_4 = sales_4 * oz_4 * np.exp(P_4)\n",
    "    profits_4 = revenue_4 * grmar4_avg\n",
    "\n",
    "\n",
    "    ###########\n",
    "    #  SKU5   # \n",
    "    ###########\n",
    "\n",
    "    intercept_5 = np.random.normal(intercept_mu_5, intercept_sigma_5)\n",
    "    B1_5   = np.random.normal(B1_mu_P2_5, B1_sigma_P2_5)\n",
    "    B2_5   = np.random.normal(B2_mu_P3_5, B2_sigma_P3_5)   \n",
    "    B3_5   = np.random.normal(B3_mu_P4_5, B3_sigma_P4_5) \n",
    "    B4_5   = np.random.normal(B4_mu_P5_5, B4_sigma_P5_5) \n",
    "\n",
    "    sales_5 = np.exp(intercept_5 \\\n",
    "            + B1_5 * P_2 \\\n",
    "            + B2_5 * P_3 \\\n",
    "            + B3_5 * P_4 \\\n",
    "            + B4_5 * P_5 \\\n",
    "            + B5_mu_D5_5 * disp5 \\\n",
    "            + B6_mu_F5_5 * feat5)\n",
    "\n",
    "    revenue_5 = sales_5 * oz_5 * np.exp(P_5)\n",
    "    profits_5 = revenue_5 * grmar5_avg\n",
    "\n",
    "        ####################\n",
    "        #  Appending SKUs  # \n",
    "        ####################\n",
    "        \n",
    "        \n",
    "    all_stats_2.append([sales_1, revenue_1, profits_1,\n",
    "                      sales_2, revenue_2, profits_2,\n",
    "                      sales_3, revenue_3, profits_3,\n",
    "                      sales_4, revenue_4, profits_4,\n",
    "                      sales_5, revenue_5, profits_5])\n",
    "\n",
    "\n",
    "results_df_2 = pd.DataFrame.from_records(all_stats_2,  columns = \n",
    "['units_sold_1','revenue_1','profits_1',\n",
    " 'units_sold_2','revenue_2','profits_2',\n",
    " 'units_sold_3','revenue_3','profits_3',\n",
    " 'units_sold_4','revenue_4','profits_4',\n",
    " 'units_sold_5','revenue_5','profits_5'])\n",
    "\n",
    "final_stats_2.append([np.exp(P_1), np.exp(P_2), np.exp(P_3),\n",
    "                    np.exp(P_4), np.exp(P_5),\n",
    "                    results_df_2['profits_1'].mean(),\n",
    "                    results_df_2['profits_2'].mean(),\n",
    "                    results_df_2['profits_3'].mean(),\n",
    "                    results_df_2['profits_4'].mean(),\n",
    "                    results_df_2['profits_5'].mean(),\n",
    "                    feat1,feat2,feat3,feat4,feat5,\n",
    "                    disp1,disp2,disp3,disp4,disp5])\n",
    "    \n",
    "final_stats_df_2 = pd.DataFrame.from_records(final_stats_2, columns =\n",
    "                ['Price per Oz_1', 'Price per Oz_2',\n",
    "                 'Price per Oz_3', 'Price per Oz_4', 'Price per Oz_5',\n",
    "                 'Profits_1', 'Profits_2', \n",
    "                 'Profits_3', 'Profits_4', 'Profits_5',\n",
    "                 'Feat_1', 'Feat_2', 'Feat_3', 'Feat_4', 'Feat_5',\n",
    "                 'Disp_1', 'Disp_2', 'Disp_3', 'Disp_4', 'Disp_5'])\n",
    "\n",
    "final_stats_df_2['Total Profits'] = final_stats_df_2['Profits_5']\\\n",
    "                                + final_stats_df_2['Profits_4']\\\n",
    "                                + final_stats_df_2['Profits_3']\\\n",
    "                                + final_stats_df_2['Profits_2']\\\n",
    "                                + final_stats_df_2['Profits_1']\n",
    "final_stats_df_2.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-proof",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-29T22:33:15.896072Z",
     "start_time": "2021-03-29T22:33:15.867668Z"
    }
   },
   "outputs": [],
   "source": [
    "final_stats_df.head(n=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
